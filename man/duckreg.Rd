% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/duckreg.R
\name{duckreg}
\alias{duckreg}
\title{Run a compressed regression with a DuckDB backend.}
\usage{
duckreg(
  fml,
  conn = NULL,
  table = NULL,
  data = NULL,
  path = NULL,
  vcov = "hc1",
  query_only = FALSE,
  data_only = FALSE
)
}
\arguments{
\item{fml}{A \code{\link[stats]{formula}} representing the relation to be
estimated. Fixed-effects should be included after a pipe, e.g
\code{fml = y ~ x1 + x2 | fe1 + f2}. Currently, only simple additive terms
are supported (i.e., no interaction terms, transformations or literals).}

\item{conn}{Connection to a DuckDB database, e.g. created with
\code{\link[DBI]{dbConnect}}. Can be either persistent (disk-backed) or
ephemeral (in-memory). If no connection is provided, then an ephemeral
connection will be created automatically and closed before the function
exits. Note that a persistent (disk-backed) database connection is
required for larger-than-RAM datasets in order to take advantage of DuckDB's
streaming functionality.}

\item{table, data, path}{Mututally exclusive arguments for specifying the data
table (object) to be queried. In order of precedence:
\itemize{
\item \code{table}: Character string giving the name of the data table in an
existing (open) DuckDB connection.
\item \code{data}: R dataframe that can be copied over to \code{conn} as a temporary
table for querying via the DuckDB query engine. Ignored if \code{table} is
provided.
\item \code{path}: Character string giving a path to the data file(s) on disk, which
will be read into \code{conn}. Internally, this string is passed to the \code{FROM}
query statement, so could (should) include file globbing for
Hive-partitioned datasets, e.g. \code{"mydata/**/.*parquet"}. For more precision,
however, it is recommended to pass the desired DuckDB reader function as
part of this string, e.g. \code{"read_parquet('mydata/**/*.parquet')"};
note the use of single quotes.
Ignored if either \code{table} or \code{data} is provided.
}}

\item{vcov}{Character string denoting the desired type of variance-
covariance correction / standard errors. At present, only "hc1"
(heteroskedasticity-consistent) are supported, which is also thus
the default.}

\item{query_only}{Logical indicating whether only the underlying compression
SQL query should be returned (i.e., no computation will be performed).
Default is \code{FALSE}.}

\item{data_only}{Logical indicating whether only the compressed dataset
should be returned (i.e., no regression is run). Default is \code{FALSE}.}
}
\value{
A list of class "duckreg" containing various slots, including a table
of coefficients (which the associated print method will display).
}
\description{
Leverages the power of DuckDB to run regressions on very large datasets,
which may not fit into R's memory. The core procedure follows Wong et al.
(2021) by reducing ("compressing") the data to a set of summary statistics
and then running frequency-weighted least squares on this smaller dataset.
Robust standard errors are computed from sufficient statistics.
}
\examples{

# A not very compelling example using a small in-memory dataset:
(mod = duckreg(Temp ~ Wind | Month, data = airquality))

Same result as lm
summary(lm(Temp ~ Wind + factor(Month), data = airquality))

# Aside: duckreg's default print method hides the "nuisance" coefficients
# like the intercept and fixed effect(s). But we can grab them if we want.
print(mod, fes = TRUE)

# Note: for a more compelling and appropriate use-case, i.e. regression on a
# big (~180 million row) dataset of Hive-partioned parquet files, see the
# package website:
# https://github.com/grantmcdermott/duckreg?tab=readme-ov-file#quickstart
}
\references{
Wong, J., Forsell, E., Lewis, R., Mao, T., & Wardrop, M. (2021).
\cite{You Only Compress Once: Optimal Data Compression for Estimating Linear Models.}
arXiv preprint arXiv:2102.11297.
Available: https://doi.org/10.48550/arXiv.2102.11297
}

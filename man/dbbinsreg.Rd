% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dbbinsreg.R
\name{dbbinsreg}
\alias{dbbinsreg}
\title{Run a binscatter regression on a database backend}
\usage{
dbbinsreg(
  fml,
  data = NULL,
  path = NULL,
  points = c(0, 0),
  line = NULL,
  linegrid = 20,
  nbins = 20,
  binspos = "qs",
  sample_frac = NULL,
  ci = TRUE,
  cb = FALSE,
  vcov = NULL,
  level = 0.95,
  nsims = 500,
  strategy = "auto",
  conn = NULL,
  verbose = getOption("dbreg.verbose", FALSE),
  dots = NULL
)
}
\arguments{
\item{fml}{A \code{\link[stats]{formula}} representing the binscatter relation.
The first variable on the RHS is the running variable; additional variables
are controls. Fixed effects go after \code{|}. Examples:
\itemize{
\item \code{y ~ x}: simple binscatter
\item \code{y ~ x + w1 + w2}: binscatter with controls
\item \code{y ~ x | fe}: binscatter with fixed effects
\item \code{y ~ x + w1 + w2 | fe}: binscatter with controls and fixed effects
}}

\item{data}{A data source: R dataframe, database table name (character), or
a lazy table object (e.g., from \code{dplyr::tbl()}) pointing to a database table.}

\item{path}{Character string giving a path to data file(s) on disk. This is
an alias for \code{data} for consistency with \code{\link{dbreg}}. Can include
file globbing for Hive-partitioned datasets, e.g.
\code{"read_parquet('mydata/**/*.parquet')"}.}

\item{points}{A vector \code{c(p, s)} specifying the polynomial degree \eqn{p} and
smoothness \eqn{s} for the points (point estimates at bin means). Default is
\code{c(0, 0)} for canonical binscatter (bin means). Set to \code{NULL} or \code{FALSE} to
suppress points. The smoothness \code{s} must satisfy \code{s <= p}.}

\item{line}{A vector \code{c(p, s)} specifying the polynomial degree \eqn{p} and
smoothness \eqn{s} for the line (evaluated on a grid within bins). Default
is \code{NULL} (no line). Set to \code{TRUE} for \code{c(0, 0)} or a vector like \code{c(1, 1)}
for piecewise linear with continuity constraints. The smoothness \eqn{s}
must satisfy \code{s <= p}.}

\item{linegrid}{Number of evaluation points per bin for the line. Default is 20.}

\item{nbins}{Integer number of bins. Default is 20.}

\item{binspos}{Bin positioning method. One of either \code{"qs"} (quantile-spaced,
equal-count bins, the default), \code{"es"} (evenly-spaced, equal-width bins),
or a numeric vector of knot positions for manual specification.}

\item{sample_frac}{Numeric in the range \verb{(0,1]}. Controls the random sampling
fraction for bin boundary computation on large datasets. If \code{NULL} (the
default), then sampling is automatic: \code{0.01} (1\%) for datasets exceeding 1
million rows and \code{1} (100\%) otherwise. Note that sampling is only used for
computing the bin boundaries, since this requires an expensive ranking
operation. The subsequent, primary regression operations use all of the
data.}

\item{ci}{Logical. Calculate standard errors and confidence intervals for points?
Default is \code{TRUE}.}

\item{cb}{Logical. Calculate simultaneous confidence bands using simulation?
Default is \code{FALSE}.}

\item{vcov}{Character string or formula for standard errors. Options are
\code{"HC1"} (default, heteroskedasticity-robust, matches
\code{\link[binsreg]{binsreg}}), \code{"iid"}, or a one-sided formula for
clustered standard errors (e.g., \code{~cluster_var}).}

\item{level}{Numeric in the range \verb{[0,1]}, giving the confidence level for
the confidence levels and/or bands. Default is \code{0.95}.}

\item{nsims}{Number of simulation draws for confidence band computation.
Default is 500. Only used when \code{cb = TRUE}.}

\item{strategy}{Acceleration strategy passed to \code{\link{dbreg}} when
smoothness is zero. Options are \code{"auto"} (default), \code{"compress"}, or
\code{"scan"}. This parameter is ignored when \code{s} (smoothness parameter in
\code{points} or \code{lines}) > 0. See \code{\link{dbreg}} for details.}

\item{conn}{Database connection. If \code{NULL} (default), an ephemeral DuckDB
connection will be created.}

\item{verbose}{Logical. Print auto strategy and progress messages to the
console? Defaults to \code{FALSE}. This can be overridden for a single call
by supplying \code{verbose = TRUE}, or set globally via
\code{options(dbreg.verbose = TRUE)}.}

\item{dots}{Alias for \code{points} for \code{\link[binsreg]{binsreg}} compatibility.
If not \code{NULL}, overrides the \code{points} argument.}
}
\value{
A list of class "dbbinsreg" containing:
\describe{
\item{points}{Data frame of the point estimates (one row per bin): \code{x}
(bin mean), \code{bin}, and \code{fit} (fitted value). If \code{ci=TRUE} in the original
call, then also includes the columns: \code{se}, \code{lwr}, and \code{upr}. Similarly,
if \code{cb=TRUE}, then includes the columns: \code{cb_lwr} and \code{cb_upr}.}
\item{line}{Data frame of the line estimates (multiple rows per bin): \code{x},
\code{bin}, \code{fit}. Only present if \code{line} is specified.}
\item{bins}{Data frame with bin boundaries: \code{id} (bin number), \code{left}
(left endpoint), \code{right} (right endpoint).}
\item{model}{The fitted \code{dbreg} model object (for points).}
\item{opt}{List of options used: \code{points}, \code{line}, \code{nbins}, \code{binspos}, etc.}
}
}
\description{
Performs binned regression entirely in SQL, returning plot-ready data with
estimated bin means or piecewise polynomial fits. The API is designed to be compatible
with the \pkg{binsreg} package by Cattaneo, Crump, Farrell, and Feng (2024).
Supports unconditional and conditional models (with controls and/or fixed effects).
}
\section{Comparison with binsreg}{


The \code{dbbinsreg} function is deeply inspired by the \pkg{binsreg}
package (Cattaneo et. al., 2024). The main difference is that
\code{dbbinsreg} performs most of its computation on a database backend,
employing various acceration strategies, which makes it particularly suitable
for large datasets (which may not fit in memory). At the same time, the
database backend introduces its own set of tradeoffs. We cover the most
important points of similarity and difference below.
\subsection{API}{

We aim to mimic the \code{\link[binsreg]{binsreg}} API as much as possible.
Key parameter mappings include:
\itemize{
\item \code{points} (alias \code{dots}): Point estimates at bin means
\itemize{
\item \code{c(0,0)}: Canonical binscatter (bin means)
\item \code{c(p,0)}: Piecewise polynomial of degree \eqn{p}, no smoothness
\item \code{c(p,s)}: Piecewise polynomial with \eqn{s} smoothness constraints
}
\item \code{line}: Same as \code{points} but evaluated on a finer grid for smooth visualization
\item \code{binspos}: Bin positioning
\itemize{
\item \code{"qs"}: Quantile-spaced (equal count)
\item \code{"es"}: Evenly-spaced (equal width)
}
}

\strong{Important:} Unlike \code{\link[binsreg]{binsreg}}, \code{dbbinsreg} does
not automatically select the IMSE-optimal number of bins. Users must specify
\code{nbins} manually. For guidance on bin selection, see
\code{\link[binsreg]{binsregselect}} or Cattaneo et al. (2024).
}

\subsection{Confidence intervals vs confidence bands}{

When \code{ci = TRUE} (default), pointwise confidence intervals (CIs) are computed
at each bin mean using standard asymptotic theory. When \code{cb = TRUE},
simultaneous confidence bands (CBs) are computed using a simulation-based
sup-\eqn{t} procedure:
\enumerate{
\item Draw \code{nsims} samples from the asymptotic distribution of the estimator
\item Compute the supremum of the \eqn{t}-statistics across all bins for each draw
\item Use the (\eqn{1-\alpha}) quantile of these suprema as the critical value
}

The confidence band is wider than pointwise CIs and provides simultaneous
coverage: with (\eqn{1-\alpha}) probability, the entire true function lies
within the band. This is useful for making statements about the overall shape
of the relationship rather than individual point estimates.

There are two important caveats, regarding \code{dbbinsreg}'s CB support:
\itemize{
\item Unlike \code{\link[binsreg]{binsreg}}, which evaluates CB on a fine
grid within each bin, \code{dbbinsreg} computes CB only at bin means (same points
as CI). This is much simpler for our backend SQL implementation and should be
sufficient for most applications.
\item CBs are currently only supported for unconstrained estimation (smoothness
\code{s = 0}). When \code{cb = TRUE} with \code{s > 0}, a warning is issued and CB is skipped.
}
}

\subsection{Note on quantile bin boundaries}{

When using quantile-spaced bins (\code{binspos = "qs"}), \code{dbbinsreg} uses SQL's
\code{NTILE()} window function, while \code{\link[binsreg]{binsreg}} uses R's
\code{\link[stats]{quantile}} with \code{type = 2}. These algorithms have slightly
different tie-breaking behavior, which can cause small differences in bin
assignments at boundaries. In practice, differences are typically <1\% and
become negligible with larger datasets. To match
\code{\link[binsreg]{binsreg}} exactly, compute quantile breaks on a subset
of data in R and pass them via the \code{binspos} argument as a numeric vector.
}
}

\examples{
\dontrun{
cw = as.data.frame(ChickWeight)

# Canonical binscatter: bin means (default)
dbbinsreg(weight ~ Time, cw, nbins = 10)

# Piecewise linear, no smoothness
dbbinsreg(weight ~ Time, cw, nbins = 10, points = c(1, 0))

# Piecewise quadratic with C1 continuity
dbbinsreg(weight ~ Time, cw, nbins = 10, points = c(2, 1))

# With line overlay for smooth visualization
dbbinsreg(weight ~ Time, cw, nbins = 10, points = c(0, 0), line = c(1, 1))

# With fixed effects (diet type)
dbbinsreg(weight ~ Time | Diet, cw, nbins = 10, points = c(1, 0))
}
}
\references{
Cattaneo, M. D., R. K. Crump, M. H. Farrell, and Y. Feng (2024).
On Binscatter. \emph{American Economic Review}, 114(5): 1488-1514.
}

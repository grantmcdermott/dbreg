% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dbbinsreg.R
\name{dbbinsreg}
\alias{dbbinsreg}
\title{Run a binscatter regression on a database backend and plot the result}
\usage{
dbbinsreg(
  fml,
  conn = NULL,
  table = NULL,
  data = NULL,
  path = NULL,
  points = c(0, 0),
  line = NULL,
  linegrid = 20,
  nbins = 20,
  binspos = "qs",
  randcut = NULL,
  ci = TRUE,
  cb = FALSE,
  vcov = NULL,
  level = 0.95,
  nsims = 500,
  strategy = "auto",
  plot = TRUE,
  verbose = getOption("dbreg.verbose", FALSE),
  dots = NULL
)
}
\arguments{
\item{fml}{A \code{\link[stats]{formula}} representing the binscatter relation.
The first variable on the RHS is the running variable; additional variables
are controls. Fixed effects go after \code{|}. Examples:
\itemize{
\item \code{y ~ x}: simple binscatter
\item \code{y ~ x + w1 + w2}: binscatter with controls
\item \code{y ~ x | fe}: binscatter with fixed effects
\item \code{y ~ x + w1 + w2 | fe}: binscatter with controls and fixed effects
}}

\item{conn}{Database connection, e.g. created with
\code{\link[DBI]{dbConnect}}. Can be either persistent (disk-backed) or
ephemeral (in-memory). If no connection is provided, then an ephemeral
\code{\link[duckdb]{duckdb}} connection will be created automatically and
closed before the function exits. Note that a persistent (disk-backed)
database connection is required for larger-than-RAM datasets in order to take
advantage of out-of-core functionality like streaming (where supported).}

\item{table, data, path}{Mutually exclusive arguments for specifying the data
table (object) to be queried. In order of precedence:
\itemize{
\item \code{table}: Character string giving the name of the data table in an
existing (open) database connection.
\item \code{data}: R dataframe that can be copied over to \code{conn} as a temporary
table for querying via the DuckDB query engine. Ignored if \code{table} is
provided.
\item \code{path}: Character string giving a path to the data file(s) on disk, which
will be read into \code{conn}. Internally, this string is passed to the \code{FROM}
query statement, so could (should) include file globbing for
Hive-partitioned datasets, e.g. \code{"mydata/**/.*parquet"}. For more precision,
however, it is recommended to pass the desired database reader function as
part of this string, e.g. \code{"read_parquet('mydata/**/*.parquet')"} for DuckDB;
note the use of single quotes.
Ignored if either \code{table} or \code{data} is provided.
}}

\item{points}{A vector \code{c(p, s)} specifying the polynomial degree \eqn{p} and
smoothness \eqn{s} for the points (point estimates at bin means). Default is
\code{c(0, 0)} for canonical binscatter (bin means). Set to \code{NULL} or \code{FALSE} to
suppress points. The smoothness \code{s} must satisfy \code{s <= p}.}

\item{line}{A vector \code{c(p, s)} specifying the polynomial degree \eqn{p} and
smoothness \eqn{s} for the line (evaluated on a grid within bins). Default
is \code{NULL} (no line). Set to \code{TRUE} for \code{c(0, 0)} or a vector like \code{c(1, 1)}
for piecewise linear with continuity constraints. The smoothness \eqn{s}
must satisfy \code{s <= p}.}

\item{linegrid}{Number of evaluation points per bin for the line. Default is 20.}

\item{nbins}{Integer number of bins. Default is 20.}

\item{binspos}{Bin positioning method. One of either \code{"qs"} (quantile-spaced,
equal-count bins, the default), \code{"es"} (evenly-spaced, equal-width bins),
or a numeric vector of knot positions for manual specification.}

\item{randcut}{Numeric in the range \verb{(0,1]}. Controls the random sampling
fraction for bin boundary computation on large datasets. If \code{NULL} (the
default), then sampling is automatic: \code{0.01} (1\%) for datasets exceeding 1
million rows and \code{1} (100\%) otherwise. Note that sampling is only used for
computing the bin boundaries, since this requires an expensive ranking
operation. The subsequent, primary regression operations use all of the
data.}

\item{ci}{Logical. Calculate standard errors and confidence intervals for points?
Default is \code{TRUE}.}

\item{cb}{Logical. Calculate simultaneous confidence bands using simulation?
Default is \code{FALSE}.}

\item{vcov}{Character string or formula for standard errors. Options are
\code{"HC1"} (default, heteroskedasticity-robust, matches
\code{\link[binsreg]{binsreg}}), \code{"iid"}, or a one-sided formula for
clustered standard errors (e.g., \code{~cluster_var}).}

\item{level}{Numeric in the range \verb{[0,1]}, giving the confidence level for
the confidence levels and/or bands. Default is \code{0.95}.}

\item{nsims}{Number of simulation draws for confidence band computation.
Default is 500. Only used when \code{cb = TRUE}.}

\item{strategy}{Acceleration strategy passed to \code{\link{dbreg}} when
smoothness is zero. Options are \code{"auto"} (default), \code{"compress"}, or
\code{"scan"}. This parameter is ignored when \code{s} (smoothness parameter in
\code{points} or \code{lines}) > 0. See \code{\link{dbreg}} for details.}

\item{plot}{Logical. If \code{TRUE} (default), a plot is produced as a side effect.
Set to \code{FALSE} to suppress plotting.}

\item{verbose}{Logical. Print auto strategy and progress messages to the
console? Defaults to \code{FALSE}. This can be overridden for a single call
by supplying \code{verbose = TRUE}, or set globally via
\code{options(dbreg.verbose = TRUE)}.}

\item{dots}{Alias for \code{points} for \code{\link[binsreg]{binsreg}} compatibility.
If not \code{NULL}, overrides the \code{points} argument.}
}
\value{
A list of class "dbbinsreg" containing:
\describe{
\item{points}{Data frame of the point estimates (one row per bin): \code{x}
(bin mean), \code{bin}, and \code{fit} (fitted value). If \code{ci=TRUE} in the original
call, then also includes the columns: \code{se}, \code{lwr}, and \code{upr}. Similarly,
if \code{cb=TRUE}, then includes the columns: \code{cb_lwr} and \code{cb_upr}.}
\item{line}{Data frame of the line estimates (multiple rows per bin): \code{x},
\code{bin}, \code{fit}. Only present if \code{line} is specified.}
\item{bins}{Data frame with bin boundaries: \code{id} (bin number), \code{left}
(left endpoint), \code{right} (right endpoint).}
\item{model}{The fitted \code{dbreg} model object (for points).}
\item{opt}{List of options used: \code{points}, \code{line}, \code{nbins}, \code{binspos}, etc.}
}
If \code{plot = TRUE} (the default), a binscatter plot is also produced as a
side effect. See \code{\link{plot.dbbinsreg}} for plot customization.
}
\description{
Performs binned regression entirely in SQL, returning plot-ready data with
estimated bin means or piecewise polynomial fits. The API is designed to be compatible
with the \pkg{binsreg} package by Cattaneo, Crump, Farrell, and Feng (2024).
Supports unconditional and conditional models (with controls and/or fixed effects).
}
\section{Comparison with binsreg}{


The \code{dbbinsreg} function is deeply inspired by the \pkg{binsreg}
package (Cattaneo et. al., 2024). The main difference is that
\code{dbbinsreg} performs most of its computation on a database backend,
employing various acceration strategies, which makes it particularly suitable
for large datasets (which may not fit in memory). At the same time, the
database backend introduces its own set of tradeoffs. We cover the most
important points of similarity and difference below.
\subsection{API}{

We aim to mimic the \code{\link[binsreg]{binsreg}} API as much as possible.
Key parameter mappings include:
\itemize{
\item \code{points} (alias \code{dots}): Point estimates at bin means
\itemize{
\item \code{c(0,0)}: Canonical binscatter (bin means)
\item \code{c(p,0)}: Piecewise polynomial of degree \eqn{p}, no smoothness
\item \code{c(p,s)}: Piecewise polynomial with \eqn{s} smoothness constraints
}
\item \code{line}: Same as \code{points} but evaluated on a finer grid for smooth visualization
\item \code{binspos}: Bin positioning
\itemize{
\item \code{"qs"}: Quantile-spaced (equal count)
\item \code{"es"}: Evenly-spaced (equal width)
}
}

\strong{Important:} Unlike \code{\link[binsreg]{binsreg}}, \code{dbbinsreg} does
not automatically select the IMSE-optimal number of bins. Users must specify
\code{nbins} manually. For guidance on bin selection, see
\code{\link[binsreg]{binsregselect}} or Cattaneo et al. (2024).
}

\subsection{Confidence intervals vs confidence bands}{

When \code{ci = TRUE} (default), pointwise confidence intervals (CIs) are computed
at each bin mean using standard asymptotic theory. When \code{cb = TRUE},
simultaneous confidence bands (CBs) are computed using a simulation-based
sup-\eqn{t} procedure:
\enumerate{
\item Draw \code{nsims} samples from the asymptotic distribution of the estimator
\item Compute the supremum of the \eqn{t}-statistics across all bins for each draw
\item Use the (\eqn{1-\alpha}) quantile of these suprema as the critical value
}

The confidence band is wider than pointwise CIs and provides simultaneous
coverage: with (\eqn{1-\alpha}) probability, the entire true function lies
within the band. This is useful for making statements about the overall shape
of the relationship rather than individual point estimates.

There are two important caveats, regarding \code{dbbinsreg}'s CB support:
\itemize{
\item Unlike \code{\link[binsreg]{binsreg}}, which evaluates CB on a fine
grid within each bin, \code{dbbinsreg} computes CB only at bin means (same points
as CI). This is much simpler for our backend SQL implementation and should be
sufficient for most applications.
\item CBs are currently only supported for unconstrained estimation (smoothness
\code{s = 0}). When \code{cb = TRUE} with \code{s > 0}, a warning is issued and CB is skipped.
}
}

\subsection{Note on quantile bin boundaries}{

When using quantile-spaced bins (\code{binspos = "qs"}), \code{dbbinsreg} uses SQL's
\code{NTILE()} window function, while \code{\link[binsreg]{binsreg}} uses R's
\code{\link[stats]{quantile}} with \code{type = 2}. These algorithms have slightly
different tie-breaking behavior, which can cause small differences in bin
assignments at boundaries. In practice, differences are typically <1\% and
become negligible with larger datasets. To match
\code{\link[binsreg]{binsreg}} exactly, compute quantile breaks on a subset
of data in R and pass them via the \code{binspos} argument as a numeric vector.
}
}

\examples{
#
## In-memory data ----

# Like `dbreg`, we can pass in-memory R data frames to an ephemeral DuckDB
# connection via the `data` argument. 

dbreg(weight ~ Diet, data = ChickWeight)

# Canonical binscatter: bin means (default)
dbbinsreg(weight ~ Time, data = ChickWeight, nbins = 10)

# For plot customization, save the model object so you can pass additional args
# to (tiny)plot.dbbinsreg
bs = dbbinsreg(weight ~ Time, data = ChickWeight, nbins = 10)
plot(bs, theme = "clean", main = "A simple binscatter example")

# Alternatively: you can also set a global (tiny)plot theme
tinyplot::tinytheme("classic")

# Piecewise linear, no smoothness
dbbinsreg(weight ~ Time, data = ChickWeight, nbins = 10, points = c(1, 0))

# Piecewise linear with continuity
dbbinsreg(weight ~ Time, data = ChickWeight, nbins = 10, points = c(1, 1))

# With line overlay for smooth visualization
dbbinsreg(weight ~ Time, data = ChickWeight, nbins = 10, points = c(1, 1), line = TRUE)

# Different line smoothness to points
dbbinsreg(weight ~ Time, data = ChickWeight, nbins = 10, points = c(0, 0), line = c(1, 1))

# With uniform confidence bands (much greater uncertainty)
set.seed(99)
dbbinsreg(weight ~ Time, data = ChickWeight, nbins = 10, cb = TRUE)

# Accounting for Diet "fixed effects" helps to resolve the situation
dbbinsreg(weight ~ Time | Diet, data = ChickWeight, nbins = 10, cb = TRUE)

#
## DBI connection ----

library(DBI)
con = dbConnect(duckdb::duckdb())
dbWriteTable(con, "cw", as.data.frame(ChickWeight))

dbbinsreg(weight ~ Time | Diet, conn = con, table = "cw", nbins = 10)
# etc.

# See ?dbreg for more connection examples

# Clean up
dbDisconnect(con)
tinyplot::tinytheme() # reset plot theme


}
\references{
Cattaneo, M. D., R. K. Crump, M. H. Farrell, and Y. Feng (2024).
On Binscatter. \emph{American Economic Review}, 114(5): 1488-1514.
}
\seealso{
\code{\link{plot.dbbinsreg}} for plot customization,
\code{\link{dbreg}} for the underlying regression engine,
\code{\link[binsreg]{binsreg}} for the original implementation.
}
